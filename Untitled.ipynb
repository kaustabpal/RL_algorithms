{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFERLIMIT = 50_000\n",
    "MINI_BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "DISCOUNT_RATE = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=BUFFERLIMIT)\n",
    "\n",
    "    def put(self, transition):\n",
    "        if(self.size() > BUFFERLIMIT):\n",
    "            self.buffer.pop()\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample(self):\n",
    "        mini_batch = random.sample(self.buffer, min(len(self.buffer), MINI_BATCH_SIZE))\n",
    "        #s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []\n",
    "        #for transition in mini_batch:\n",
    "        #    s,a,r,s_prime,done = transition\n",
    "        return mini_batch\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet:\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, input_shape=(observation_space,), activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(action_space, activation = \"linear\")           \n",
    "        ])\n",
    "        self.model.compile(optimizer =Adam(lr=LEARNING_RATE), loss=\"mse\")\n",
    "    \n",
    "    def summary(self):\n",
    "        return self.model.summary()\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.model.get_weights()\n",
    "    \n",
    "    def set_weights(self, other):\n",
    "        return self.model.set_weights(other.model.get_weights())\n",
    "    \n",
    "    def train(self,x,y):\n",
    "        return self.model.train_on_batch(x,y)\n",
    "        \n",
    "    def predict(self,inp):\n",
    "        return self.model.predict(inp)\n",
    "    \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        coin = np.random.random_sample()\n",
    "        if(coin<=epsilon):\n",
    "            return np.random.randint(low=0, high=2) # returns values between 0 and 1\n",
    "        else:\n",
    "            return np.argmax(self.model.predict(obs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_target, memory):\n",
    "    mini_batch = memory.sample()\n",
    "    x = []\n",
    "    y = []\n",
    "    for s,a,r,s_prime,done in mini_batch:\n",
    "        max_future_q = np.max(q_target.predict(tf.constant(s,shape=(1,4))))\n",
    "        new_q = r + DISCOUNT_RATE*max_future_q*np.invert(done)\n",
    "        current_q = q.predict(tf.constant(s,shape=(1,4))) # current q_values for the actions\n",
    "        current_q[0][a] = new_q # updating the q_value of the chosen action to that of the target q value\n",
    "        x.append(s)\n",
    "        y.append(current_q)\n",
    "        \n",
    "    x = tf.constant(x,shape=(len(x), input_shape))\n",
    "    y = tf.constant(y, shape=(len(y), output_shape))\n",
    "    q.train(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_env, q):\n",
    "    test_s = test_env.reset()\n",
    "    test_done = False\n",
    "    test_score = 0\n",
    "    while not test_done:\n",
    "        test_a = np.argmax(q.predict(tf.constant(test_s,shape=(1,4))))\n",
    "        test_s_prime, test_r, test_done, test_info =test_env.step(test_a)\n",
    "        test_s = test_s_prime\n",
    "        test_score += test_r\n",
    "        test_env.render()\n",
    "        time.sleep(1/120)\n",
    "        if test_done:\n",
    "            break\n",
    "    return test_score       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0. Score: 10.0\n",
      "Episode: 1. Score: 10.0\n",
      "Episode: 2. Score: 10.0\n",
      "Episode: 3. Score: 10.0\n",
      "Episode: 4. Score: 10.0\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    EPISODES = 5 # total number of episodes to train for\n",
    "    env = gym.make(\"CartPole-v1\") # select environment. Currently only tested on CartPole-v1\n",
    "    test_env = gym.make(\"CartPole-v1\")\n",
    "    test_env = wrappers.Monitor(test_env, './videos/' + str(time.time()) + '/', video_callable=lambda episode_id: n_epi%10==0)\n",
    "    input_shape = env.observation_space.shape[0]\n",
    "    output_shape = env.action_space.n\n",
    "    q = Qnet(input_shape,output_shape)\n",
    "    q_target = Qnet(input_shape, output_shape)\n",
    "    q_target.set_weights(q)\n",
    "    memory = ReplayBuffer()\n",
    "    update_target_interval = 20\n",
    "    ep_vec = [] # Vector to store ep_number for plotting\n",
    "    score_vec = [] # vector to store score in this episode for plotting\n",
    "    \n",
    "    for n_epi in range(EPISODES):\n",
    "        epsilon = max(0.01, (1 - 0.99/(200)*n_epi))\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        score = 0.\n",
    "        \n",
    "        while not done:\n",
    "            a = q.sample_action(tf.constant(s,shape=(1,4)), epsilon) #select action from updated q net\n",
    "            s_prime, r, done, info = env.step(a)\n",
    "            memory.put((s,a,r,s_prime,int(done))) # insert into experience replay\n",
    "            s = s_prime\n",
    "            score += r\n",
    "            #env.render()\n",
    "            time.sleep(1/120)\n",
    "            if done:\n",
    "                break\n",
    "        if(memory.size() >= 1000 ):\n",
    "            train(q, q_target, memory)    # update q net\n",
    "\n",
    "        # after k eps update target_q params with q_net\n",
    "        if(n_epi!=0 and n_epi%update_target_interval == 0):\n",
    "            q_target.set_weights(q)\n",
    "            #print(\"Episode: {}. Score: {}\".format(ep_vec[-1],score_vec[-1]))\n",
    "\n",
    "        ep_vec.append(n_epi)\n",
    "        score_vec.append(test(test_env,q))\n",
    "        print(\"Episode: {}. Score: {}\".format(ep_vec[-1],score_vec[-1]))\n",
    "    test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch = memory.sample()\n",
    "x = []\n",
    "y = []\n",
    "for s,a,r,s_prime,done in mini_batch:\n",
    "    x.append(s)\n",
    "x= tf.constant(x,shape=(len(x),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q.predict(tf.reshape(x[0],shape=(1,4)))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for s,a,r,s_prime,done in memory.buffer:\n",
    "    x.append(s)\n",
    "x= tf.constant(x,shape=(len(x),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[1,2,3,4],[5,6,7,8]]\n",
    "q.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ =[]\n",
    "a_ =[]\n",
    "for transition in buff:\n",
    "    s,a,r,s_prime, done = transition\n",
    "    s_.append(s)\n",
    "    a_.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Qnet(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = q.sample_action(tmp2, 1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = tf.constant(env.reset(),shape=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = Qnet(4,2)\n",
    "q2.set_weights(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(buff)*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7b71230370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.model.load_weights('./Model/dqn_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = q.predict(tf.constant(env.reset(), shape=(1,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00858856,  0.00359186]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
